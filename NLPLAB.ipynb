{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d373ba19-42bc-48c8-bfb8-3d8be9ed1c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 561.5/561.5 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, multiprocess, fsspec, huggingface-hub, datasets\n",
      "\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "  Attempting uninstall: fsspec\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   ---------------------------------------- 5/5 [datasets]\n",
      "\n",
      "Successfully installed datasets-4.0.0 fsspec-2025.3.0 huggingface-hub-0.34.4 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2025.3.2 requires fsspec==2025.3.2.*, but you have fsspec 2025.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f2b93-57b7-47c2-86bb-179704c41459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sentence_tokenizer(paragraph):\n",
    "  pattern='[\\u0964!?.][^0-9.0-9]'\n",
    "  sentences=re.split(pattern,paragraph)\n",
    "  ends=re.findall(pattern,paragraph)\n",
    "  res=[]\n",
    "  for sentence in sentences:\n",
    "    if ends==[]:\n",
    "      break\n",
    "    end=ends.pop(0)\n",
    "    res.append(sentence.strip() + end)\n",
    "  return res\n",
    "\n",
    "\n",
    "def word_tokenizer(sentence):\n",
    "    url_pattern = r'https?://(?:www\\.)?[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}'\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "  \n",
    "    phone_pattern = r'(?:\\+?[0-9\\u0966-\\u096F]{1,3}[\\s-]?)?[0-9\\u0966-\\u096F]{10}'\n",
    "\n",
    "    # Time format: 10:30 or १०:३०\n",
    "    time_pattern = r'[0-9\\u0966-\\u096F]{1,2}:[0-9\\u0966-\\u096F]{2}'\n",
    "\n",
    "    # Decimal and whole numbers\n",
    "    latin_number = r'[0-9]+(?:\\.[0-9]+)?'\n",
    "    devnag_number = r'[\\u0966-\\u096F]+(?:\\.[\\u0966-\\u096F]+)?'\n",
    "\n",
    "    # Punctuation\n",
    "    punctuation = r'[!?\\.\\u0964\\,\"\\'\\+-]'\n",
    "\n",
    "    # Hindi / Devanagari words\n",
    "    hindi_word = fr'[\\u0900-\\u0963\\u0965-\\u096F]+[^!?\\.\\u0964\\,\"\\'\\+-]'\n",
    "    english_word = r'[a-zA-Z]+'\n",
    "\n",
    "\n",
    "    # Emojis (basic unicode emoji range)\n",
    "    emoji_pattern = r'[\\U0001F300-\\U0001FAFF\\U00002700-\\U000027BF]'\n",
    "\n",
    "    # Final combined pattern\n",
    "    pattern = fr'{email_pattern}|{url_pattern}|{phone_pattern}|{time_pattern}|{latin_number}|{devnag_number}|{punctuation}|{hindi_word}|{emoji_pattern}|{english_word}'\n",
    "\n",
    "    return re.findall(pattern, sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce4a574-39dc-4665-87d2-a96eae4fd7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86eee491-69bb-48af-bcd1-691499d1837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ai4bharat/IndicCorpV2\", \"indiccorp_v2\", split=\"hin_Deva\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2c73a7-1a83-4893-97d5-1e14bdc8e7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    num_shards: 3\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928be32-ed2a-4ab9-a2e9-12cb5f90aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words_csv = \"hindi_tokenized_words2.csv\"           \n",
    "reconstructed_csv = \"hindi_reconstructed_sentences2.csv\"     \n",
    "re_sentence_csv = \"hindi_re_sentence_tokenized2.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548e435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9242e4dd-8335-45d4-9128-e56b69cb77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lines = 10_000_000   \n",
    "log_every = 100_000      \n",
    "flush_every = 10_000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b246d-72d3-43bf-9867-7b0555721fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   1%|▍                                    | 103222/10000000 [00:45<16:29, 10003.54sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 100,000 | re-sentences written: 101,167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   2%|▊                                    | 203208/10000000 [01:05<10:28, 15592.18sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 200,000 | re-sentences written: 202,345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   3%|█                                    | 302431/10000000 [01:21<10:22, 15573.74sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 300,000 | re-sentences written: 303,632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   4%|█▍                                   | 401866/10000000 [01:35<09:47, 16344.16sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 400,000 | re-sentences written: 404,876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   5%|█▊                                   | 503065/10000000 [01:52<10:01, 15782.19sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 500,000 | re-sentences written: 506,095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   6%|██▎                                   | 603105/10000000 [02:12<26:24, 5930.14sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 600,000 | re-sentences written: 607,285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   7%|██▌                                  | 703142/10000000 [02:26<10:30, 14745.39sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 700,000 | re-sentences written: 708,410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   8%|██▉                                  | 803077/10000000 [02:39<10:13, 14995.52sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 800,000 | re-sentences written: 809,543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:   9%|███▎                                 | 902276/10000000 [02:54<09:21, 16189.12sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 900,000 | re-sentences written: 910,865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  10%|███▌                                | 1002679/10000000 [03:13<09:41, 15464.44sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,000,000 | re-sentences written: 1,012,480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  11%|███▊                               | 1101922/10000000 [03:33<1:39:16, 1493.87sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,100,000 | re-sentences written: 1,113,648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  12%|████▎                               | 1202029/10000000 [03:45<11:34, 12674.90sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,200,000 | re-sentences written: 1,214,912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  13%|████▋                               | 1302975/10000000 [04:02<09:18, 15576.14sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,300,000 | re-sentences written: 1,316,278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  14%|█████                               | 1401989/10000000 [04:15<09:31, 15035.14sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,400,000 | re-sentences written: 1,417,482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  15%|█████▍                              | 1501954/10000000 [04:28<09:03, 15625.36sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,500,000 | re-sentences written: 1,518,738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  16%|█████▊                              | 1601115/10000000 [04:40<03:41, 37994.63sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,600,000 | re-sentences written: 1,619,867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  17%|██████▎                              | 1702333/10000000 [04:59<14:38, 9441.45sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,700,000 | re-sentences written: 1,720,961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  18%|██████▍                             | 1803284/10000000 [05:13<08:22, 16300.82sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,800,000 | re-sentences written: 1,822,159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  19%|██████▊                             | 1903424/10000000 [05:25<08:09, 16553.66sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 1,900,000 | re-sentences written: 1,923,351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  20%|███████▏                            | 2002048/10000000 [05:39<08:12, 16238.37sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,000,000 | re-sentences written: 2,024,726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  21%|███████▌                            | 2103150/10000000 [05:53<07:51, 16732.99sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,100,000 | re-sentences written: 2,125,989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  22%|████████▏                            | 2202084/10000000 [06:15<42:04, 3089.47sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,200,000 | re-sentences written: 2,227,158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  23%|████████▎                           | 2301984/10000000 [06:27<08:30, 15085.64sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,300,000 | re-sentences written: 2,328,147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  24%|████████▋                           | 2403576/10000000 [06:50<07:44, 16349.42sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,400,000 | re-sentences written: 2,429,350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  25%|█████████                           | 2503076/10000000 [07:08<07:47, 16052.69sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,500,000 | re-sentences written: 2,530,613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  26%|█████████▎                          | 2603331/10000000 [07:21<07:41, 16015.45sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,600,000 | re-sentences written: 2,631,850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  27%|█████████▉                           | 2702466/10000000 [07:45<48:44, 2495.36sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,700,000 | re-sentences written: 2,733,003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  28%|██████████                          | 2801652/10000000 [08:00<09:09, 13106.06sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,800,000 | re-sentences written: 2,834,133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  29%|██████████▍                         | 2903094/10000000 [08:14<07:43, 15304.86sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 2,900,000 | re-sentences written: 2,935,256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  30%|██████████▊                         | 3002609/10000000 [08:27<07:26, 15664.02sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,000,000 | re-sentences written: 3,036,490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  31%|███████████▏                        | 3102734/10000000 [08:40<07:23, 15549.74sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,100,000 | re-sentences written: 3,137,666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  32%|███████████▌                        | 3200221/10000000 [08:52<07:03, 16072.59sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,200,000 | re-sentences written: 3,239,155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  33%|███████████▉                        | 3302639/10000000 [09:11<09:29, 11761.55sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,300,000 | re-sentences written: 3,340,299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  34%|████████████▏                       | 3402118/10000000 [09:30<07:01, 15655.63sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,400,000 | re-sentences written: 3,441,516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  35%|████████████▌                       | 3502715/10000000 [09:50<06:50, 15837.32sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,500,000 | re-sentences written: 3,542,771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  36%|████████████▉                       | 3602427/10000000 [10:09<08:09, 13067.64sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,600,000 | re-sentences written: 3,644,003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  37%|█████████████▎                      | 3702325/10000000 [10:26<07:47, 13476.55sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,700,000 | re-sentences written: 3,745,409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  38%|██████████████                       | 3802063/10000000 [10:56<26:50, 3848.36sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,800,000 | re-sentences written: 3,846,892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  39%|██████████████                      | 3902965/10000000 [11:25<07:42, 13171.53sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 3,900,000 | re-sentences written: 3,948,232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  40%|██████████████▍                     | 4002073/10000000 [11:53<06:07, 16325.99sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,000,000 | re-sentences written: 4,049,622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  41%|██████████████▊                     | 4102583/10000000 [12:21<06:55, 14200.65sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,100,000 | re-sentences written: 4,150,924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  42%|███████████████▏                    | 4202828/10000000 [12:38<05:53, 16417.39sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,200,000 | re-sentences written: 4,252,254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  43%|███████████████▍                    | 4302126/10000000 [13:27<2:21:11, 672.58sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,300,000 | re-sentences written: 4,353,490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  44%|███████████████▊                    | 4401754/10000000 [13:45<07:45, 12029.30sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,400,000 | re-sentences written: 4,454,794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  45%|████████████████▏                   | 4502153/10000000 [14:09<06:00, 15240.59sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,500,000 | re-sentences written: 4,556,020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  46%|████████████████▌                   | 4603447/10000000 [14:27<05:23, 16699.46sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,600,000 | re-sentences written: 4,657,483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  47%|████████████████▉                   | 4702447/10000000 [14:44<05:46, 15284.04sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,700,000 | re-sentences written: 4,758,728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  48%|█████████████████▎                  | 4799515/10000000 [15:00<05:14, 16509.80sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,800,000 | re-sentences written: 4,859,858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  49%|█████████████████▋                  | 4902805/10000000 [15:21<06:56, 12240.57sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 4,900,000 | re-sentences written: 4,961,075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  50%|██████████████████                  | 5001983/10000000 [15:35<05:32, 15010.65sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,000,000 | re-sentences written: 5,062,236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  51%|██████████████████▎                 | 5102262/10000000 [15:50<05:20, 15290.91sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,100,000 | re-sentences written: 5,163,440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  52%|██████████████████▋                 | 5202716/10000000 [16:06<05:03, 15830.93sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,200,000 | re-sentences written: 5,264,829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 24d6b126-8d15-49b3-a848-568709a51bc9)')' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D7C5179F90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 54dde743-4a24-4d82-88c0-bfb72e90f2c9)')' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 2195ff2c-b16f-4ce2-90dc-5354749bca13)')' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)), '(Request ID: 307386f0-fc09-4824-a97d-b029fe6f1d82)')' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Got disconnected from remote data host. Retrying in 5sec [1/20]\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f21213a8-f104-4587-82c3-a437aca55fab)')' thrown while requesting GET https://huggingface.co/datasets/ai4bharat/IndicCorpV2/resolve/2d7285e6ce14fdb3fb2449c9f89427b9f582ac3f/data/hi-1.txt\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Processed original sentences:  53%|███████████████████                 | 5302851/10000000 [17:56<05:00, 15619.09sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,300,000 | re-sentences written: 5,366,095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  54%|███████████████████▉                 | 5401871/10000000 [18:20<14:13, 5387.40sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,400,000 | re-sentences written: 5,467,321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  55%|███████████████████▊                | 5502470/10000000 [18:33<05:03, 14833.38sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,500,000 | re-sentences written: 5,568,506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  56%|████████████████████▏               | 5603233/10000000 [18:51<04:43, 15498.80sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,600,000 | re-sentences written: 5,670,211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  57%|████████████████████▌               | 5702417/10000000 [19:08<04:17, 16680.29sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,700,000 | re-sentences written: 5,771,333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  58%|████████████████████▉               | 5801379/10000000 [19:25<04:34, 15272.08sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,800,000 | re-sentences written: 5,872,507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  59%|█████████████████████▊               | 5901997/10000000 [20:02<54:49, 1245.63sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 5,900,000 | re-sentences written: 5,973,686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  60%|█████████████████████▌              | 6002812/10000000 [20:21<05:33, 11992.59sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,000,000 | re-sentences written: 6,074,749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  61%|█████████████████████▉              | 6102076/10000000 [20:40<04:15, 15258.28sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,100,000 | re-sentences written: 6,175,979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  62%|██████████████████████▎             | 6202932/10000000 [20:59<03:48, 16602.05sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,200,000 | re-sentences written: 6,277,254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  63%|██████████████████████▋             | 6301733/10000000 [21:21<03:54, 15748.05sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,300,000 | re-sentences written: 6,378,416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  64%|███████████████████████             | 6399175/10000000 [21:45<03:33, 16885.03sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,400,000 | re-sentences written: 6,479,907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  65%|████████████████████████             | 6503291/10000000 [22:21<06:50, 8509.83sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,500,000 | re-sentences written: 6,581,372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  66%|███████████████████████▊            | 6599501/10000000 [22:38<04:12, 13465.03sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,600,000 | re-sentences written: 6,682,635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  67%|████████████████████████            | 6700893/10000000 [22:58<04:42, 11694.39sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,700,000 | re-sentences written: 6,783,926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  68%|████████████████████████▍           | 6801986/10000000 [23:21<03:23, 15686.29sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,800,000 | re-sentences written: 6,885,150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  69%|████████████████████████▊           | 6902388/10000000 [23:44<03:08, 16417.04sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 6,900,000 | re-sentences written: 6,986,232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  70%|█████████████████████████▉           | 7002293/10000000 [24:12<08:20, 5986.24sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,000,000 | re-sentences written: 7,087,463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  71%|█████████████████████████▌          | 7101938/10000000 [24:34<03:13, 14945.40sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,100,000 | re-sentences written: 7,188,717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  72%|█████████████████████████▉          | 7202169/10000000 [24:52<02:45, 16930.89sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,200,000 | re-sentences written: 7,289,878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  73%|██████████████████████████▎         | 7302930/10000000 [25:13<02:43, 16528.82sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,300,000 | re-sentences written: 7,391,035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  74%|██████████████████████████▋         | 7402493/10000000 [25:33<02:49, 15364.42sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,400,000 | re-sentences written: 7,492,333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  75%|███████████████████████████▊         | 7503158/10000000 [26:05<14:39, 2837.67sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,500,000 | re-sentences written: 7,593,573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  76%|███████████████████████████▎        | 7601884/10000000 [26:21<02:43, 14673.00sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,600,000 | re-sentences written: 7,694,882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  77%|███████████████████████████▋        | 7702535/10000000 [26:34<02:26, 15646.22sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,700,000 | re-sentences written: 7,796,234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  78%|████████████████████████████        | 7801652/10000000 [26:46<02:11, 16715.37sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,800,000 | re-sentences written: 7,897,500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  79%|████████████████████████████▍       | 7903211/10000000 [27:01<02:10, 16045.52sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 7,900,000 | re-sentences written: 7,998,697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  80%|█████████████████████████████▌       | 8002141/10000000 [27:24<29:00, 1148.03sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,000,000 | re-sentences written: 8,099,796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  81%|█████████████████████████████▏      | 8102832/10000000 [27:40<03:03, 10315.36sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,100,000 | re-sentences written: 8,201,100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  82%|█████████████████████████████▌      | 8202216/10000000 [27:55<01:53, 15865.76sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,200,000 | re-sentences written: 8,302,197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  83%|█████████████████████████████▉      | 8301871/10000000 [28:13<01:43, 16358.35sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,300,000 | re-sentences written: 8,403,493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  84%|██████████████████████████████▏     | 8401513/10000000 [28:28<01:45, 15219.23sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,400,000 | re-sentences written: 8,504,787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  85%|██████████████████████████████▌     | 8501995/10000000 [28:47<01:38, 15261.76sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,500,000 | re-sentences written: 8,605,760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  86%|███████████████████████████████▊     | 8602379/10000000 [29:11<03:30, 6654.87sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,600,000 | re-sentences written: 8,707,458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  87%|███████████████████████████████▎    | 8702917/10000000 [29:26<01:23, 15444.32sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,700,000 | re-sentences written: 8,808,958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  88%|███████████████████████████████▋    | 8802424/10000000 [29:43<01:21, 14738.14sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,800,000 | re-sentences written: 8,910,512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  89%|████████████████████████████████    | 8903004/10000000 [30:02<01:06, 16394.04sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 8,900,000 | re-sentences written: 9,012,367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  90%|████████████████████████████████▍   | 9001795/10000000 [30:21<01:00, 16478.64sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,000,000 | re-sentences written: 9,113,540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  91%|█████████████████████████████████▋   | 9101561/10000000 [30:51<07:25, 2014.68sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,100,000 | re-sentences written: 9,214,833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  92%|█████████████████████████████████▏  | 9202652/10000000 [31:11<00:57, 13975.46sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,200,000 | re-sentences written: 9,315,917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  93%|█████████████████████████████████▍  | 9302386/10000000 [31:30<00:41, 16634.16sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,300,000 | re-sentences written: 9,417,202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  94%|█████████████████████████████████▊  | 9402938/10000000 [31:52<00:36, 16268.47sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,400,000 | re-sentences written: 9,518,369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  95%|██████████████████████████████████▏ | 9502458/10000000 [32:13<00:34, 14601.20sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,500,000 | re-sentences written: 9,619,496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  96%|███████████████████████████████████▌ | 9602352/10000000 [32:36<04:40, 1415.18sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,600,000 | re-sentences written: 9,720,692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  97%|██████████████████████████████████▉ | 9702603/10000000 [32:47<00:22, 13134.45sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,700,000 | re-sentences written: 9,822,038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  98%|███████████████████████████████████▎| 9802839/10000000 [33:03<00:12, 16076.89sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,800,000 | re-sentences written: 9,923,074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences:  99%|███████████████████████████████████▋| 9901662/10000000 [33:20<00:06, 15440.00sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 9,900,000 | re-sentences written: 10,024,427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed original sentences: 100%|████████████████████████████████████| 10000000/10000000 [33:33<00:00, 4966.85sent/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] original sentences processed: 10,000,000 | re-sentences written: 10,125,710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- File Paths ----------\n",
    "tokenized_words_csv = \"hindi_tokenized_words.csv\"\n",
    "reconstructed_csv = \"hindi_reconstructed_sentences.csv\"\n",
    "re_sentence_csv = \"hindi_re_sentence.csv\"\n",
    "\n",
    "max_lines = 10_000_000\n",
    "log_every = 100_000\n",
    "flush_every = 50_000\n",
    "\n",
    "with open(tokenized_words_csv, \"w\", encoding=\"utf-8\", newline='') as words_file, \\\n",
    "     open(reconstructed_csv, \"w\", encoding=\"utf-8\", newline='') as recon_file, \\\n",
    "     open(re_sentence_csv, \"w\", encoding=\"utf-8\", newline='') as re_sent_file:\n",
    "\n",
    "    words_writer = csv.writer(words_file)\n",
    "    recon_writer = csv.writer(recon_file)\n",
    "    re_sent_writer = csv.writer(re_sent_file)\n",
    "\n",
    "    # Headers\n",
    "    words_writer.writerow([\"token\"])\n",
    "    recon_writer.writerow([\"reconstructed_sentence\"])\n",
    "    re_sent_writer.writerow([\"re_sentence\"])\n",
    "\n",
    "    count_original_sentences = 0\n",
    "    count_re_sentences = 0\n",
    "\n",
    "    pbar = tqdm(total=max_lines, desc=\"Processing\", unit=\"sent\")\n",
    "\n",
    "    for row in dataset:                      \n",
    "        text = row.get(\"text\", \"\") or \"\"\n",
    "        sentences = sentence_tokenizer(text)  \n",
    "\n",
    "        for sent in sentences:\n",
    "            #  word-tokenize this sentence\n",
    "            tokens = word_tokenizer(sent)\n",
    "\n",
    "            #  individual tokens (one per row)\n",
    "            for token in tokens:\n",
    "                words_writer.writerow([token])\n",
    "\n",
    "            # reconstructed sentence (space-joined)\n",
    "            reconstructed = \" \".join(tokens)\n",
    "            recon_writer.writerow([reconstructed])\n",
    "\n",
    "            # sentence-tokenize the reconstructed string\n",
    "            re_sentences = sentence_tokenizer(reconstructed)\n",
    "            if re_sentences:\n",
    "                for rs in re_sentences:\n",
    "                    re_sent_writer.writerow([rs])\n",
    "                    count_re_sentences += 1\n",
    "            else:\n",
    "                re_sent_writer.writerow([reconstructed])\n",
    "                count_re_sentences += 1\n",
    "\n",
    "            count_original_sentences += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if count_original_sentences % flush_every == 0:\n",
    "                words_file.flush()\n",
    "                recon_file.flush()\n",
    "                re_sent_file.flush()\n",
    "\n",
    "            if count_original_sentences % log_every == 0:\n",
    "                print(f\"[LOG] original sentences processed: {count_original_sentences:,} | re-sentences written: {count_re_sentences:,}\")\n",
    "\n",
    "            if count_original_sentences >= max_lines:\n",
    "                break\n",
    "\n",
    "        if count_original_sentences >= max_lines:\n",
    "            break\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "print(f\"Done! Sentences processed: {count_original_sentences:,}, Re-sentences: {count_re_sentences:,}\")\n",
    "print(f\"Files saved:\\n - {tokenized_words_csv}\\n - {reconstructed_csv}\\n - {re_sentence_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb106f0-bc07-48d4-9e21-0b76a4f5d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb0e807-d9db-47dc-9d05-18a248e35da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('hindi_tokenized_words2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c38487-1173-4e3d-9a44-2acef59a9fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190001440, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738a9c2b-8ea2-469c-af25-b74a9a491faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73366781</th>\n",
       "      <td>हुए</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137130712</th>\n",
       "      <td>वे</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86120992</th>\n",
       "      <td>रीयूनियन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61333423</th>\n",
       "      <td>से</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100765490</th>\n",
       "      <td>तो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148551164</th>\n",
       "      <td>मोर्टार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137683431</th>\n",
       "      <td>और</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023666</th>\n",
       "      <td>हिंसा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80981008</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85803718</th>\n",
       "      <td>पश्चात</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token\n",
       "73366781        हुए \n",
       "137130712        वे \n",
       "86120992   रीयूनियन \n",
       "61333423         से \n",
       "100765490        तो \n",
       "148551164   मोर्टार \n",
       "137683431        और \n",
       "28023666      हिंसा \n",
       "80981008          15\n",
       "85803718     पश्चात "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03e4a99-f73a-44c5-992a-a93b77acf9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1402691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7822780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token\n",
       "count   190001334\n",
       "unique    1402691\n",
       "top             ।\n",
       "freq      7822780"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08196397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen_re=pd.read_csv('hindi_reconstructed_sentences2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc498dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e957f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstructed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4928966</th>\n",
       "      <td>इसीलिए  वहां  के  हालात  इतने  भयावह  हो  गये ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389105</th>\n",
       "      <td>वहीं  एक  अन्य  घटना  में  उसी  तालुका  के  को...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906085</th>\n",
       "      <td>गूंगी - बहरी  विधवा  महिला  करीब  बीस  दिन  से...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996197</th>\n",
       "      <td>नर्मदा  तट  तिलवाराघाट  से  भक्तों  की  टोली  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753037</th>\n",
       "      <td>सीएम  ने  कहा  कि  सोमवार  को  पीएम  के  साथ  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712829</th>\n",
       "      <td>समुद्धि  महाराज  ने  कहा  कि  मंगलवार  को  महा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667536</th>\n",
       "      <td>वैसे  जल्द  ही  दीया  अपने  बच्चे  को  जन्म  द...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594323</th>\n",
       "      <td>ऐसे  में  मनाली  पुलिस  ने  बीमारी  से  हुई  म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8890955</th>\n",
       "      <td>उधर , वरुण  ने  निर्वाचन  आयोग  के  नोटिस  का ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081493</th>\n",
       "      <td>व्यापार  मंडल  अध्यक्ष  विवेक  अग्रवाल , राजेन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916671</th>\n",
       "      <td>यानी  उनका  दिमाग  इनोवेशन  के  लिहाज  से  फर्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145996</th>\n",
       "      <td>पुलिस  के  अनुसार  जहांगीर  पुत्र  नूर  मोहम्म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280927</th>\n",
       "      <td>आकाश  बादलों  से  भर  गया  है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952414</th>\n",
       "      <td>इसके  बाद  एसटीएफ  ने  अपनी  रिपोर्ट  में  कहा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795828</th>\n",
       "      <td>इस  टैबलेट  का  नाम  POP 7 LTE है .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995026</th>\n",
       "      <td>जिसमें  जयसिंह  नगर  विजय  घोषित  रही ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237644</th>\n",
       "      <td>फ्लैट  स्टील  में  ज्यादा  एकीकरण  होगा , जहां...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359878</th>\n",
       "      <td>44 लाख  वसूली  को  नगर  पालिका  की  ओर  से  दो...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611063</th>\n",
       "      <td>वीसी  में  उपनिदेशक  कृषि  श्री  जी .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374422</th>\n",
       "      <td>जागरण  संवाददाता: पटियाला  पंजाब  प्रदेश  कांग...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reconstructed_sentence\n",
       "4928966  इसीलिए  वहां  के  हालात  इतने  भयावह  हो  गये ...\n",
       "7389105  वहीं  एक  अन्य  घटना  में  उसी  तालुका  के  को...\n",
       "4906085  गूंगी - बहरी  विधवा  महिला  करीब  बीस  दिन  से...\n",
       "8996197  नर्मदा  तट  तिलवाराघाट  से  भक्तों  की  टोली  ...\n",
       "1753037  सीएम  ने  कहा  कि  सोमवार  को  पीएम  के  साथ  ...\n",
       "712829   समुद्धि  महाराज  ने  कहा  कि  मंगलवार  को  महा...\n",
       "4667536  वैसे  जल्द  ही  दीया  अपने  बच्चे  को  जन्म  द...\n",
       "8594323  ऐसे  में  मनाली  पुलिस  ने  बीमारी  से  हुई  म...\n",
       "8890955  उधर , वरुण  ने  निर्वाचन  आयोग  के  नोटिस  का ...\n",
       "4081493  व्यापार  मंडल  अध्यक्ष  विवेक  अग्रवाल , राजेन...\n",
       "4916671  यानी  उनका  दिमाग  इनोवेशन  के  लिहाज  से  फर्...\n",
       "2145996  पुलिस  के  अनुसार  जहांगीर  पुत्र  नूर  मोहम्म...\n",
       "4280927                    आकाश  बादलों  से  भर  गया  है ।\n",
       "952414   इसके  बाद  एसटीएफ  ने  अपनी  रिपोर्ट  में  कहा...\n",
       "6795828                इस  टैबलेट  का  नाम  POP 7 LTE है .\n",
       "7995026            जिसमें  जयसिंह  नगर  विजय  घोषित  रही ।\n",
       "2237644  फ्लैट  स्टील  में  ज्यादा  एकीकरण  होगा , जहां...\n",
       "8359878  44 लाख  वसूली  को  नगर  पालिका  की  ओर  से  दो...\n",
       "611063               वीसी  में  उपनिदेशक  कृषि  श्री  जी .\n",
       "5374422  जागरण  संवाददाता: पटियाला  पंजाब  प्रदेश  कांग..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen_re.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5768c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'वहीं  एक  अन्य  घटना  में  उसी  तालुका  के  कोडिम्बाला  गांव  के  निवासी  70 वर्षीय  एक  व्यक्ति  ने  एक  पेड़  से  लटक  कर  कथित  तौर  पर  आत्महत्या  कर  ली .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen_re.iloc[7389105].reconstructed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d20ce29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstructed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9479602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstructed_sentence\n",
       "count                10000000\n",
       "unique                9479602\n",
       "top                         .\n",
       "freq                    44424"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen_re.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99846693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen_cn=pd.read_csv('hindi_re_sentence_tokenized2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28d74245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'हम  इसे  जितना  सरल  रखेंगे , उतना  ही  बेहतर  होगा .'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen_cn.iloc[8].re_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb965e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstructed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>इनेलो  1987 में  उस  वक्त  ऐसे  ही  दोराहे  पर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>हालांकि  तब  पार्टी  पर  देवीलाल  की  मजबूत  प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989 में  देवीलाल  केन्द्र  की  राजनीति  में  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>उन  परिस्थितियों  में  देवीलाल  ने  कड़ा  निर्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उस  समय  रणजीत  की  नाराजगी  के  चलते  उनके  स...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              reconstructed_sentence\n",
       "0  इनेलो  1987 में  उस  वक्त  ऐसे  ही  दोराहे  पर...\n",
       "1  हालांकि  तब  पार्टी  पर  देवीलाल  की  मजबूत  प...\n",
       "2  1989 में  देवीलाल  केन्द्र  की  राजनीति  में  ...\n",
       "3  उन  परिस्थितियों  में  देवीलाल  ने  कड़ा  निर्...\n",
       "4  उस  समय  रणजीत  की  नाराजगी  के  चलते  उनके  स..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.read_csv(\"hindi_tokenized_words2.csv\") \n",
    "df_sentences = pd.read_csv(\"hindi_reconstructed_sentences2.csv\")\n",
    "df_words.head()\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f20ae620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['token'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_words.columns)\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f02916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 10,000,000\n",
      "Total words: 190,001,440\n",
      "Total characters (no spaces): 863,708,929.0\n",
      "Average sentence length: 19.00 words/sentence\n",
      "Average word length: 4.55 characters/word\n",
      "Type/Token Ratio (no punctuation in TTR): 0.0074\n"
     ]
    }
   ],
   "source": [
    "total_sentences = len(df_sentences)\n",
    "\n",
    "total_words = len(df_words)\n",
    "\n",
    "total_chars = df_words['token'].str.len().sum()\n",
    "\n",
    "avg_sentence_length = total_words / total_sentences\n",
    "\n",
    "avg_word_length = total_chars / total_words\n",
    "\n",
    "punctuations = set(string.punctuation) | set(['।', '’', '‘', '“', '”'])  \n",
    "tokens_no_punc = df_words[~df_words['token'].isin(punctuations)]\n",
    "unique_tokens_no_punc = tokens_no_punc['token'].nunique()\n",
    "ttr_no_punc = unique_tokens_no_punc / total_words\n",
    "\n",
    "# Print\n",
    "print(f\"Total sentences: {total_sentences:,}\")\n",
    "print(f\"Total words: {total_words:,}\")\n",
    "print(f\"Total characters (no spaces): {total_chars:,}\")\n",
    "print(f\"Average sentence length: {avg_sentence_length:.2f} words/sentence\")\n",
    "print(f\"Average word length: {avg_word_length:.2f} characters/word\")\n",
    "print(f\"Type/Token Ratio (no punctuation in TTR): {ttr_no_punc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
